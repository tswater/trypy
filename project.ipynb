{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extracting the data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np \n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "# file = '/shared_space/trypy/BioClimp.tif'\n",
    "# file = '/shared_space/trypy/nlcd2016.tif'\n",
    "# file = '/shared_space/trypy/sand_mean_rootzone.tif'\n",
    "# file = '/shared_space/trypy/trydata.h5'\n",
    "# file = '/shared_space/trypy/clay_mean_rootzone.tif'\n",
    "# file = '/shared_space/trypy/NED.vrt'\n",
    "# file = '/shared_space/trypy/om_mean_surface.tif '\n",
    "# file = '/shared_space/trypy/silt_mean_rootzone.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# import the bioclim files \n",
    "\n",
    "\n",
    "file = '/shared_space/trypy/BioClimp.tif'\n",
    "#Open up access to the file\n",
    "fp = rasterio.open(file)\n",
    "\n",
    "data = np.zeros((30,2707,6362)) # the size of the fp is used \n",
    "for i in range(20):\n",
    "    print(type(i))\n",
    "    data[i,:,:] = fp.read(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2707, 6362)\n",
      "(2707, 6362)\n"
     ]
    }
   ],
   "source": [
    "# dem data \n",
    "file = '/shared_space/trypy/dem.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[20,:,:] = fp.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2707, 6362)\n"
     ]
    }
   ],
   "source": [
    "# nlcd206 data \n",
    "file = '/shared_space/trypy/nlcd2016.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[29,:,:] = fp.read(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2707, 6362)\n"
     ]
    }
   ],
   "source": [
    "# sand mean rootzone \n",
    "file = '/shared_space/trypy/sand_mean_rootzone.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[22,:,:] = fp.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2707, 6362)\n"
     ]
    }
   ],
   "source": [
    "# clay mean rootzone\n",
    "file = '/shared_space/trypy/clay_mean_rootzone.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[23,:,:] = fp.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2707, 6362)\n"
     ]
    }
   ],
   "source": [
    "# om mean surface\n",
    "file = '/shared_space/trypy/om_mean_surface.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[24,:,:] = fp.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2707, 6362)\n"
     ]
    }
   ],
   "source": [
    "# silt mean rootzone \n",
    "file = '/shared_space/trypy/silt_mean_rootzone.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[21,:,:] = fp.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evi each season\n",
    "file = '/shared_space/trypy/evi_winter.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[25,:,:] = fp.read(1)\n",
    "\n",
    "file = '/shared_space/trypy/evi_fall.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[26,:,:] = fp.read(1)\n",
    "\n",
    "file = '/shared_space/trypy/evi_spring.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[27,:,:] = fp.read(1)\n",
    "\n",
    "file = '/shared_space/trypy/evi_summer.tif'\n",
    "fp = rasterio.open(file)\n",
    "data[28,:,:] = fp.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TRY data\n",
    "# The bounding box for US\n",
    "top = 49.3457868 # north lat\n",
    "left = -124.7844079 # west long\n",
    "right = -66.9513812 # east long\n",
    "bottom =  24.7433195 # south lat\n",
    "\n",
    "# The File \n",
    "file = 'trypy/trydata.h5'\n",
    "fp_try = h5py.File(file,'r')\n",
    "\n",
    "# Create U.S. Only Mask\n",
    "lats = fp_try['lat'][:]\n",
    "lons = fp_try['lon'][:]\n",
    "mUS = (lats>bottom) & (lats<top) & (lons>left) & (lons<right)\n",
    "\n",
    "#Remove nodata and create xylem dataset\n",
    "xyl = fp_try['xylem'][:]\n",
    "x_mask = (mUS & (xyl!=-9999))\n",
    "xyl_us = xyl[x_mask]\n",
    "x_lat = fp_try['lat'][x_mask]\n",
    "x_lon = fp_try['lon'][x_mask]\n",
    "\n",
    "#Remove nodata and create root dataset\n",
    "r = fp_try['root'][:]\n",
    "r_mask = (mUS & (r!=-9999))\n",
    "r_us = r[r_mask]\n",
    "r_lat = fp_try['lat'][r_mask]\n",
    "r_lon = fp_try['lon'][r_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to remove invalid data while keeping track of the x,y location\n",
    "def valid(a,baseshape):\n",
    "    # a is a 2D array, with dimensions [num features,num samples]\n",
    "    # baseshape is a tuple for the original spatial shape of the array\n",
    "    # this function returns a list of valid datapoints with shape [numvalid samples, num features]\n",
    "    # it also returns 2 vectors, assigning x,y positions to each sample\n",
    "    x1=np.ones(baseshape)\n",
    "    y1=np.ones(baseshape)\n",
    "    n = x1.size\n",
    "    nin = np.shape(a)[1]\n",
    "    for r in range(baseshape[0]):\n",
    "        x1[r,:]=r\n",
    "    for c in range(baseshape[1]):\n",
    "        y1[:,c]=c\n",
    "    x1 = np.reshape(x1,(n))\n",
    "    y1 = np.reshape(y1,(n))\n",
    "    mask = np.ones(np.shape(x1), dtype=bool)\n",
    "    for e in range(nin):\n",
    "        mask = mask & (~np.isnan(a[:,e]) & (a[:,e]>-2500) & (a[:,e]<10**10))\n",
    "    c0 = a[mask,0]\n",
    "    l = np.shape(c0)[0]\n",
    "    aout=np.ones((l,nin))                               \n",
    "    for e in range(nin):\n",
    "        aout[:,e]=a[mask,e]\n",
    "    x1 = x1[mask]\n",
    "    y1 = y1[mask]\n",
    "    return aout, x1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k= 20+10\n",
    "#flatten to 2D for PCA and RF\n",
    "flat = np.reshape(data,(k,2707*6362))\n",
    "\n",
    "#Remove invalid data in prep for PCA and RF\n",
    "val_data, x_pos,y_pos = valid(np.transpose(flat),(2707,6362))\n",
    "\n",
    "#Remove NLCD since it is categorical and thus not well suited to PCA\n",
    "Xsites = val_data[:,0:29]\n",
    "\n",
    "#standardization\n",
    "Xsites_std = (Xsites - np.mean(Xsites,axis=0))/np.std(Xsites,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to determine optimal number of components\n",
    "\"\"\"\n",
    "#optimal number of components\n",
    "LIST=[]\n",
    "for i in range(k-1):\n",
    "    pca = sklearn.decomposition.PCA(n_components=i)\n",
    "    pca.fit(Xsites_std)\n",
    "    tmp= np.sum(pca.explained_variance_ratio_)\n",
    "    LIST.append(tmp)\n",
    "    print(str(i)+':'+str(tmp))\n",
    "    \n",
    "x= np.linspace(1,k-1,k-1)\n",
    "plt.plot(x,LIST)\n",
    "plt.title('optimal PCA number')\n",
    "plt.xlabel('number of principle components')\n",
    "plt.ylabel('expalined variance ratio')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the optimal PCA\n",
    "pca = sklearn.decomposition.PCA(n_components=15)\n",
    "pca.fit(Xsites_std)\n",
    "Xsites_std_pca = pca.transform(Xsites_std)\n",
    "print('Done0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest -- PCA, No Removal of outliers\n",
    "''' Prep for Random Forest '''\n",
    "X_x = [[] for i in range(15)]\n",
    "X_r = [[] for i in range(15)]\n",
    "y_x = []\n",
    "y_r = []\n",
    "# Extract the feature values at each location of our plant trait samples xylem\n",
    "for x in range(948):\n",
    "    pos = fp.index(x_lon[x],x_lat[x])\n",
    "    pos_linear = np.where((x_pos == pos[0])&(y_pos == pos[1]))\n",
    "    if (pos_linear[0].size == 0):\n",
    "        continue\n",
    "    for i in range(15):\n",
    "         X_x[i].append(float(Xsites_std_pca[pos_linear[0][0],i]))\n",
    "    y_x.append(xyl_us[x])\n",
    "    \n",
    "# Do the Same for Rooting depth\n",
    "for x in range(1573):\n",
    "    pos = fp.index(r_lon[x],r_lat[x])\n",
    "    pos_linear = np.where((x_pos == pos[0])&(y_pos == pos[1]))\n",
    "    if (pos_linear[0].size == 0):\n",
    "        continue\n",
    "    for i in range(15):\n",
    "        X_r[i].append(float(Xsites_std_pca[pos_linear[0],i]))\n",
    "    y_r.append(r_us[x])\n",
    "    \n",
    "X_x = np.transpose(np.array(X_x))\n",
    "X_r = np.transpose(np.array(X_r))\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestRegressor(random_state=1,n_estimators=100,oob_score=True)\n",
    "clf.fit(X_x,y_x)\n",
    "xscore = clf.oob_score_\n",
    "xpredict = clf.predict(Xsites_std_pca)\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestRegressor(random_state=1,n_estimators=100,oob_score=True)\n",
    "clf.fit(X_r,y_r)\n",
    "rscore = clf.oob_score_\n",
    "rpredict = clf.predict(Xsites_std_pca)\n",
    "\n",
    "# Map the predictions\n",
    "r_map = np.ones((2707,6362))*float('nan')\n",
    "for i in range(x_pos.size):\n",
    "    r_map[int(x_pos[i]),int(y_pos[i])]=rpredict[i]\n",
    "\n",
    "x_map = np.ones((2707,6362))*float('nan')\n",
    "for i in range(x_pos.size):\n",
    "    x_map[int(x_pos[i]),int(y_pos[i])]=xpredict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Random Forest -- PCA, with Removal of outliers\n",
    "''' Prep for Random Forest '''\n",
    "X_r = [[] for i in range(15)]\n",
    "y_r = []\n",
    "# Extract the feature values at each location for Rooting depth\n",
    "for x in range(1573):\n",
    "    pos = fp.index(r_lon[x],r_lat[x])\n",
    "    pos_linear = np.where((x_pos == pos[0])&(y_pos == pos[1]))\n",
    "    if (pos_linear[0].size == 0):\n",
    "        continue\n",
    "    if (r_us[x]>np.percentile(r_us,98)):\n",
    "        continue\n",
    "    for i in range(15):\n",
    "        X_r[i].append(float(Xsites_std_pca[pos_linear[0],i]))\n",
    "    y_r.append(r_us[x])\n",
    "\n",
    "X_r = np.transpose(np.array(X_r))\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestRegressor(random_state=1,n_estimators=100,oob_score=True)\n",
    "clf.fit(X_r,y_r)\n",
    "rscore96 = clf.oob_score_\n",
    "rpredict = clf.predict(Xsites_std_pca)\n",
    "\n",
    "# Map the predictions\n",
    "r_map96 = np.ones((2707,6362))*float('nan')\n",
    "for i in range(x_pos.size):\n",
    "    r_map96[int(x_pos[i]),int(y_pos[i])]=rpredict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest --No PCA with Removal of outliers\n",
    "''' Prep for Random Forest '''\n",
    "X_x = [[] for i in range(30)]\n",
    "X_r = [[] for i in range(30)]\n",
    "y_x = []\n",
    "y_r = []\n",
    "# Extract the feature values at each location of our plant trait samples xylem\n",
    "for x in range(948):\n",
    "    pos = fp.index(x_lon[x],x_lat[x])\n",
    "    pos_linear = np.where((x_pos == pos[0])&(y_pos == pos[1]))\n",
    "    if (pos_linear[0].size == 0):\n",
    "        continue\n",
    "    for i in range(30):\n",
    "         X_x[i].append(float(val_data[pos_linear[0][0],i]))\n",
    "    y_x.append(xyl_us[x])\n",
    "    \n",
    "# Do the Same for Rooting depth\n",
    "for x in range(1573):\n",
    "    pos = fp.index(r_lon[x],r_lat[x])\n",
    "    pos_linear = np.where((x_pos == pos[0])&(y_pos == pos[1]))\n",
    "    if (pos_linear[0].size == 0):\n",
    "        continue\n",
    "    if (r_us[x]>np.percentile(r_us,98)):\n",
    "        continue\n",
    "    for i in range(30):\n",
    "        X_r[i].append(float(val_data[pos_linear[0],i]))\n",
    "    y_r.append(r_us[x])\n",
    "    \n",
    "X_x = np.transpose(np.array(X_x))\n",
    "X_r = np.transpose(np.array(X_r))\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestRegressor(random_state=1,n_estimators=100,oob_score=True)\n",
    "clf.fit(X_x,y_x)\n",
    "xscore_nopca = clf.oob_score_\n",
    "xpredict = clf.predict(val_data)\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestRegressor(random_state=1,n_estimators=100,oob_score=True)\n",
    "clf.fit(X_r,y_r)\n",
    "rscore_nopca = clf.oob_score_\n",
    "rpredict = clf.predict(val_data)\n",
    "\n",
    "# Map the predictions\n",
    "r_map_nopca = np.ones((2707,6362))*float('nan')\n",
    "for i in range(x_pos.size):\n",
    "    r_map[int(x_pos[i]),int(y_pos[i])]=rpredict[i]\n",
    "\n",
    "x_map_nopca = np.ones((2707,6362))*float('nan')\n",
    "for i in range(x_pos.size):\n",
    "    x_map[int(x_pos[i]),int(y_pos[i])]=xpredict[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Tif: PCA without removal Rooting Depth\n",
    "#fp is the fp from the first few cell blocks\n",
    "with rasterio.Env():\n",
    "    profile = fp.profile\n",
    "    profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "    with rasterio.open('trypy/rooting_depth_pca.tif', 'w', **profile) as dst:\n",
    "        dst.write(r_map.astype(rasterio.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Tif: PCA xylem\n",
    "with rasterio.Env():\n",
    "    profile = fp.profile\n",
    "    profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "    with rasterio.open('trypy/xylem.tif', 'w', **profile) as dst:\n",
    "        dst.write(x_map.astype(rasterio.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Tif: PCA with removal Rooting Depth\n",
    "with rasterio.Env():\n",
    "    profile = fp.profile\n",
    "    profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "    with rasterio.open('trypy/rooting_depth_pca_removal.tif', 'w', **profile) as dst:\n",
    "        dst.write(r_map96.astype(rasterio.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Tif: No PCA Rooting Depth\n",
    "with rasterio.Env():\n",
    "    profile = fp.profile\n",
    "    profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "    with rasterio.open('trypy/rooting_depth_nopca_removal.tif', 'w', **profile) as dst:\n",
    "        dst.write(r_map_nopca.astype(rasterio.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Tif: No PCA Xylem\n",
    "with rasterio.Env():\n",
    "    profile = fp.profile\n",
    "    profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "    with rasterio.open('trypy/xylem_nopca.tif', 'w', **profile) as dst:\n",
    "        dst.write(x_map_nopca.astype(rasterio.float32), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARY OF OOB SCORES\n",
    "Rooting Depth:\n",
    "    PCA without removal of outliers      .594\n",
    "    PCA with removal of outliers         .642\n",
    "    No PCA with removal of outliers      .652\n",
    "Xylem\n",
    "    PCA (without removal of outliers)    .474\n",
    "    no PCA (without removal of outliers) .519"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
